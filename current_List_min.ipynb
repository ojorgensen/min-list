{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b199cf8568ad45d185bf313310a01ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f365b9a3ec9e416babf587f652fc598f",
              "IPY_MODEL_80568ba67d0441ffa8926b758ef5c508",
              "IPY_MODEL_e916098b5cd846c5aa6c261f32a0848c"
            ],
            "layout": "IPY_MODEL_7f499b6345f04986b206e8ce083ee97b"
          }
        },
        "f365b9a3ec9e416babf587f652fc598f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d08cfd66dd948f98acf4059fe24304c",
            "placeholder": "​",
            "style": "IPY_MODEL_5412321b106f48aa84205aa6cf690b00",
            "value": "  0%"
          }
        },
        "80568ba67d0441ffa8926b758ef5c508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f478f883a5d4a009ab57fa816f022bc",
            "max": 2001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_283c98aeb9f146cebf21310b88c0ca42",
            "value": 0
          }
        },
        "e916098b5cd846c5aa6c261f32a0848c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05f5dc841de4afb8abe89f3033cd210",
            "placeholder": "​",
            "style": "IPY_MODEL_9212913a5ab94406b2efcfbeec003132",
            "value": " 0/2001 [00:01&lt;?, ?it/s]"
          }
        },
        "7f499b6345f04986b206e8ce083ee97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d08cfd66dd948f98acf4059fe24304c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5412321b106f48aa84205aa6cf690b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f478f883a5d4a009ab57fa816f022bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283c98aeb9f146cebf21310b88c0ca42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f05f5dc841de4afb8abe89f3033cd210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9212913a5ab94406b2efcfbeec003132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Lens Setup"
      ],
      "metadata": {
        "id": "Cyg1hujmSsN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This setup is copied from Neel's main demo colab notebook for Transformer Lens, which can be found here: https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/Main_Demo.ipynb#scrollTo=V-IJnEFkEBPa"
      ],
      "metadata": {
        "id": "gQAPyZwFTedH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE0kPpLgSoYS",
        "outputId": "ef15b302-c698-4e87-e569-10d5ade0e7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-gbv8ihwx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-gbv8ihwx\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 006599b30fd6950b3b07c54eabbdaa7c36939595\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.1 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (4.25.1)\n",
            "Requirement already satisfied: fancy-einsum<0.0.4,>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (0.0.3)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.7.1 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (2.8.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.3.5)\n",
            "Requirement already satisfied: wandb<0.14.0,>=0.13.5 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (0.13.7)\n",
            "Requirement already satisfied: rich<13.0.0,>=12.6.0 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (12.6.0)\n",
            "Requirement already satisfied: torch<2.0,>=1.10 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.21.6)\n",
            "Requirement already satisfied: torchtyping<0.2.0,>=0.1.4 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (0.1.4)\n",
            "Requirement already satisfied: einops<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (21.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (0.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.25.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2022.11.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (0.3.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.1.5->transformer-lens==0.2.0) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.1.5->transformer-lens==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich<13.0.0,>=12.6.0->transformer-lens==0.2.0) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich<13.0.0,>=12.6.0->transformer-lens==0.2.0) (4.4.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich<13.0.0,>=12.6.0->transformer-lens==0.2.0) (2.6.1)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from torchtyping<0.2.0,>=0.1.4->transformer-lens==0.2.0) (2.13.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.25.1->transformer-lens==0.2.0) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.25.1->transformer-lens==0.2.0) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.25.1->transformer-lens==0.2.0) (2022.6.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (0.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (3.19.6)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (0.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (3.1.30)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (1.12.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (57.4.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (1.0.11)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (6.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (4.0.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (5.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: circuitsvis in /usr/local/lib/python3.8/dist-packages (1.35.0)\n",
            "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from circuitsvis) (5.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.8/dist-packages (from circuitsvis) (1.21.6)\n",
            "Requirement already satisfied: torch<2,>=1 in /usr/local/lib/python3.8/dist-packages (from circuitsvis) (1.13.0+cu116)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1->circuitsvis) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "import google.colab\n",
        "IN_COLAB = True\n",
        "print(\"Running as a Colab notebook\")\n",
        "%pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "%pip install circuitsvis\n",
        "\n",
        "# PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "# # Install another version of node that makes PySvelte work way faster\n",
        "# !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "# %pip install git+https://github.com/neelnanda-io/PySvelte.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYz6nQxGTVqK",
        "outputId": "16a225f6-ea66-4c33-d565-a9d67811283e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchtyping import TensorType as TT\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "EQCFCA9oTYx0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "FtkbozUL6VSH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ],
      "metadata": {
        "id": "51h3PflcUJqY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ],
      "metadata": {
        "id": "CVIz1ooNUFy5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "NIuIY0mEURJ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "try:\n",
        "  mkdir(Path('/content/'))\n",
        "except:\n",
        "  pass\n",
        "root = Path('/content/a')\n",
        "try:\n",
        "  os.mkdir(root)\n",
        "except:\n",
        "  pass\n",
        "large_root = Path('/content/b')\n",
        "try:\n",
        "  os.mkdir(large_root)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "HbhjeVgo-mua"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Model Training Class\n",
        "This class will be used to train general models, given training and test data as inputs."
      ],
      "metadata": {
        "id": "lRXUhaBP5_ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New code for Neel-style task\n",
        "\n",
        "class ModelTrainer:\n",
        "  \"\"\"\n",
        "  Warning: only use this to train a model once! Create a new instance if you need to retrain (I think)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    self.run_name = f\"grok_{int(time.time())}\"\n",
        "    self.save_every = 1000\n",
        "    self.cfg = cfg\n",
        "    self.model = HookedTransformer(self.cfg).to(device)\n",
        "    try:\n",
        "      os.mkdir(root/self.run_name)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    print(\"device =\", device)\n",
        "\n",
        "  def cross_entropy_high_precision(self, logits, labels):\n",
        "      self.logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
        "      self.prediction_logprobs = torch.gather(self.logprobs, index=labels[:, None], dim=-1)\n",
        "      self.loss = -torch.mean(self.prediction_logprobs)\n",
        "      return self.loss\n",
        "\n",
        "\n",
        "  def full_loss(self, data, labels):\n",
        "      # Take the final position only\n",
        "      # Note: Should think about making this more generalisable?\n",
        "      self.logits = self.model(data)[:, -1]\n",
        "      return self.cross_entropy_high_precision(self.logits, labels)\n",
        "\n",
        "  def train_model(self, train, test, train_labels, test_labels, optimizer, scheduler):  \n",
        "    self.optimizer = optimizer\n",
        "    self.scheduler = scheduler\n",
        "    self.train_losses = []\n",
        "    self.test_losses = []\n",
        "    for epoch in tqdm.tqdm(range(2001)):\n",
        "        self.train_loss = self.full_loss(train, train_labels)\n",
        "        self.test_loss = self.full_loss(test, test_labels)\n",
        "        self.train_losses.append(self.train_loss.item())\n",
        "        self.test_losses.append(self.test_loss.item())\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "          \n",
        "        if epoch%self.save_every == 0:\n",
        "            save_dict = {\n",
        "                    'model': self.model.state_dict(),\n",
        "                    'optimizer': self.optimizer.state_dict(),\n",
        "                    'scheduler': self.scheduler.state_dict(),\n",
        "                    'train_loss': self.train_loss,\n",
        "                    'test_loss': self.test_loss,\n",
        "                    'epoch': epoch,\n",
        "            }\n",
        "            torch.save(save_dict, root/self.run_name/f\"{epoch}.pth\")\n",
        "            print(f\"Saved model to {root/run_name/f'{epoch}.pth'}\")\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "          plt.semilogy(list([l for l in self.train_losses]), color=\"blue\")\n",
        "          plt.semilogy(list([l for l in self.test_losses]), color=\"red\")\n",
        "          display.clear_output(wait=True)\n",
        "          display.display(pl.gcf())\n",
        "          time.sleep(0.01)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print(f\"Epoch: {epoch}. Loss: {self.train_loss}\")\n",
        "    return self.model"
      ],
      "metadata": {
        "id": "yZz2hqtT5-xb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimum of three numbers, up to n = 100"
      ],
      "metadata": {
        "id": "FxiWRBULUXgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture: embedding, single transformer block, unembed."
      ],
      "metadata": {
        "id": "9iDy77QoVYpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.transformer import TransformerDecoderLayer\n",
        "p = 100\n",
        "d_vocab = p+1\n",
        "n_ctx = 3\n",
        "\n",
        "tiny_cfg1 = HookedTransformerConfig(\n",
        "    d_model=64,\n",
        "    d_head=64//1,\n",
        "    n_heads=1,\n",
        "    d_mlp=4*64,\n",
        "    n_layers=1,\n",
        "    n_ctx=n_ctx,\n",
        "    act_fn=\"relu\", #solu_ln\n",
        "    d_vocab=d_vocab,\n",
        "    normalization_type=None, #\"LN\",\n",
        "    seed=23,  # Now we're training a custom model, it's good to set the seed to get reproducible results. It defaults to 42.\n",
        ")\n",
        "\n",
        "trainer1 = ModelTrainer(tiny_cfg1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG4h5B9zVWuB",
        "outputId": "bc63f473-b6cd-48b0-fc3f-5a9edd7c702c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n",
            "device = cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train test split, where our dataset encompasses all tuples of length 2 of numbers smaller than p\n",
        "def gen_train_test(frac_train=0.7, num=p, seed=0):\n",
        "    # Generate train and test split\n",
        "    pairs = [(i, j, k) for i in range(num) for j in range(num) for k in range(num)]\n",
        "    random.seed(seed)\n",
        "    random.shuffle(pairs)\n",
        "    div = int(frac_train*len(pairs))\n",
        "    return pairs[:div], pairs[div:]\n",
        "\n",
        "\n",
        "train1, test1 = gen_train_test(frac_train=0.7, num=p, seed=0)\n",
        "train1 = torch.tensor(train1)\n",
        "test1 = torch.tensor(test1)\n",
        "\n",
        "fn = lambda x,y,z:min(x,y,z)\n",
        "train_labels1 = torch.tensor([fn(i, j,k) for i, j, k in train1]).to('cuda')\n",
        "test_labels1 = torch.tensor([fn(i, j,k) for i, j, k  in test1]).to('cuda')\n",
        "\n",
        "optimizer1 = torch.optim.AdamW(trainer1.model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=1.0)\n",
        "scheduler1 = optim.lr_scheduler.LambdaLR(optimizer1, lambda step: min(step/10, 1))\n",
        "num_epochs1 = 2000\n"
      ],
      "metadata": {
        "id": "xMHw3qwMEFHC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.train_model(train1, test1, train_labels1, test_labels1, optimizer1, scheduler1)\n"
      ],
      "metadata": {
        "id": "BjSALHzWVa2L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "b199cf8568ad45d185bf313310a01ee7",
            "f365b9a3ec9e416babf587f652fc598f",
            "80568ba67d0441ffa8926b758ef5c508",
            "e916098b5cd846c5aa6c261f32a0848c",
            "7f499b6345f04986b206e8ce083ee97b",
            "5d08cfd66dd948f98acf4059fe24304c",
            "5412321b106f48aa84205aa6cf690b00",
            "8f478f883a5d4a009ab57fa816f022bc",
            "283c98aeb9f146cebf21310b88c0ca42",
            "f05f5dc841de4afb8abe89f3033cd210",
            "9212913a5ab94406b2efcfbeec003132"
          ]
        },
        "outputId": "681f0423-8efd-4d7f-b3b6-d309d37c0fb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2001 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b199cf8568ad45d185bf313310a01ee7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-52c52314761f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-a1336a6a8a47>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train, test, train_labels, test_labels, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             }\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"{epoch}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved model to {root/run_name/f'{epoch}.pth'}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run_name' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to fix the above for memory issues!! Unsure why it isn't working now when it was before? Maybe need to clear stuff between runs?"
      ],
      "metadata": {
        "id": "2IM7wG-pDceQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vs2NaDQZZQAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New code for Neel-style task\n",
        "\n",
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "run_name = f\"grok_{int(time.time())}\"\n",
        "save_every = 1000\n",
        "try:\n",
        "  os.mkdir(root/run_name)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "print(\"device =\", device)\n",
        "\n",
        "def cross_entropy_high_precision(logits, labels):\n",
        "    logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
        "    prediction_logprobs = torch.gather(logprobs, index=labels[:, None], dim=-1)\n",
        "    loss = -torch.mean(prediction_logprobs)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def full_loss(model, data, labels):\n",
        "    # Take the final position only\n",
        "    logits = model(data)[:, -1]\n",
        "    return cross_entropy_high_precision(logits, labels)\n",
        "\n",
        "def train_model(model, train, test, train_labels, test_labels, tiny_optimizer, scheduler):\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  for epoch in tqdm.tqdm(range(2001)):\n",
        "      train_loss = full_loss(model, train, train_labels)\n",
        "      test_loss = full_loss(model, test, test_labels)\n",
        "      train_losses.append(train_loss.item())\n",
        "      test_losses.append(test_loss.item())\n",
        "\n",
        "      train_loss.backward()\n",
        "      tiny_optimizer.step()\n",
        "      scheduler.step()\n",
        "      tiny_optimizer.zero_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "        \n",
        "      if epoch%save_every == 0:\n",
        "          save_dict = {\n",
        "                  'model': model.state_dict(),\n",
        "                  'optimizer': tiny_optimizer.state_dict(),\n",
        "                  'scheduler': scheduler.state_dict(),\n",
        "                  'train_loss': train_loss,\n",
        "                  'test_loss': test_loss,\n",
        "                  'epoch': epoch,\n",
        "          }\n",
        "          torch.save(save_dict, root/run_name/f\"{epoch}.pth\")\n",
        "          print(f\"Saved model to {root/run_name/f'{epoch}.pth'}\")\n",
        "      \n",
        "      if epoch % 100 == 0:\n",
        "        plt.semilogy(list([l for l in train_losses]), color=\"blue\")\n",
        "        plt.semilogy(list([l for l in test_losses]), color=\"red\")\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(pl.gcf())\n",
        "        time.sleep(0.01)\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch}. Loss: {train_loss}\")\n",
        "\n",
        "train_model(tiny_model, train, test, train_labels, test_labels, tiny_optimizer, scheduler)"
      ],
      "metadata": {
        "id": "5LawrPULZV40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nIJ3UHhQaz7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing the Model"
      ],
      "metadata": {
        "id": "9PB6aiQPa_d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Inference\n",
        "torch.argmax(tiny_model(torch.tensor([50, 47, 5]))[0][-1])"
      ],
      "metadata": {
        "id": "qFTogUVibE1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_logits, ex_cache = tiny_model.run_with_cache(torch.tensor([50, 47, 5]), remove_batch_dim = True)"
      ],
      "metadata": {
        "id": "r2a6Rb6Jbgd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems to work - let's try to understand how this works, to see if we could reverse engineer it.\n",
        "\n",
        "First, let's look at the attention pattern for our single head."
      ],
      "metadata": {
        "id": "8smuQ2sxbnNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex_logits[0][1][50]"
      ],
      "metadata": {
        "id": "DrLJm5-YcVdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_pattern = ex_cache[\"pattern\", 0, \"attn\"]"
      ],
      "metadata": {
        "id": "A5SXvJ2GdvtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_logits(model, input):\n",
        "  input = torch.tensor(input)\n",
        "  logits, cache = model.run_with_cache(input, remove_batch_dim = True)\n",
        "  fig, ax = plt.subplots(figsize=(40,4))\n",
        "  ax.plot(logits[0][-1].cpu().detach().numpy())\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D0q9vA-U2WgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(tiny_model(torch.tensor([12,11,10]))[0][-1])"
      ],
      "metadata": {
        "id": "Agcu1I8R3wSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_logits(tiny_model, [12,11,10])"
      ],
      "metadata": {
        "id": "ale3Hl4O25Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import circuitsvis as cv\n",
        "print(attn_pattern)\n",
        "cv.attention.attention_patterns(tokens = [\"50\", \"47\", \"5\"], attention = attn_pattern)\n"
      ],
      "metadata": {
        "id": "vIii3UDzeIID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_attn_pattern(model, input):\n",
        "  input = torch.tensor(input)\n",
        "  logits, cache = model.run_with_cache(input, remove_batch_dim = True)\n",
        "  attn_pattern = cache[\"pattern\", 0, \"attn\"]\n",
        "  return cv.attention.attention_patterns(tokens = [str(t) for t in list(input.detach().cpu().numpy())], attention = attn_pattern)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hDAvqO7Vm7cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_attn_pattern(tiny_model, [20,35,50])"
      ],
      "metadata": {
        "id": "ERZcTUKknqIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm going to look at the extent to which the OV circuit is just doing copying. I'm going to steal some of Neel's example to do this (from his Medium Example in Main Demo)."
      ],
      "metadata": {
        "id": "4CZZX7HCrXWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OV_copying_score(model):\n",
        "  OV_circuit_all_heads = model.OV\n",
        "  OV_circuit_all_heads_eigenvalues = OV_circuit_all_heads.eigenvalues \n",
        "  # print(OV_circuit_all_heads_eigenvalues.shape)\n",
        "  # print(OV_circuit_all_heads_eigenvalues.dtype)\n",
        "  OV_copying_score2 = OV_circuit_all_heads_eigenvalues.sum(dim=-1).real / OV_circuit_all_heads_eigenvalues.abs().sum(dim=-1)\n",
        "  return OV_copying_score2\n"
      ],
      "metadata": {
        "id": "YDkcy6ovrT-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can find the OV copying score for a single model. Would be interesting to plot this against number of iterations, as well as how it changes when we change certain parameters of the model."
      ],
      "metadata": {
        "id": "PNrOhRqAsclL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a slightly different measure of the copying score."
      ],
      "metadata": {
        "id": "LOir_Gb31Ckd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OV_full_copying_score(model):\n",
        "  OV_circuit_all_heads = model.OV\n",
        "  full_OV_circuit = model.embed.W_E @ OV_circuit_all_heads @ model.unembed.W_U\n",
        "  print(full_OV_circuit)\n",
        "  full_OV_circuit_eigenvalues = full_OV_circuit.eigenvalues\n",
        "  full_OV_copying_score = full_OV_circuit_eigenvalues.sum(dim=-1).real / full_OV_circuit_eigenvalues.abs().sum(dim=-1)\n",
        "  return full_OV_copying_score\n",
        "\n",
        "OV_full_copying_score(tiny_model)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "fzBlHn_fk_Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoYPB5W32R14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These give pretty high values for copying, which is what we might expect to occur. This gives a possible explanation for how the model is working: it is simply  "
      ],
      "metadata": {
        "id": "4E_RR-aa1iX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing what happens if we simply embed and then unembed\n",
        "def embed_unembed_copying_score(model):\n",
        "  print(model.embed.W_E.shape, model.unembed.W_U.shape)\n",
        "  nothing = FactoredMatrix(model.embed.W_E, model.unembed.W_U)\n",
        "  print(nothing.shape)\n",
        "  nothing_eigenvalues = nothing.eigenvalues\n",
        "  nothing_score = nothing_eigenvalues.sum(dim=-1).real / nothing_eigenvalues.abs().sum(dim=-1)\n",
        "  return nothing_score\n",
        "\n",
        "embed_unembed_copying_score(tiny_model)"
      ],
      "metadata": {
        "id": "mANM50i95UEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_aafTTLi9Hc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to check this further, but this seems to suggest the OV matrix is doing more \"copying\" than simply the embed and unembed matrices composed together? Is this because it's taking into account the fact that some \n",
        "\n",
        "Experiments to do to look at this further:\n",
        "1. Vary internal dimension\n",
        "2. Compare to the task of \"just pick the last element\". Particularly, the copying score for the embed / unembed circuit."
      ],
      "metadata": {
        "id": "3h9uWLOc74lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: make it so that the code to train a model is wrapped in some function. Currently not working besides my original example.\n",
        "\n",
        "from torch.nn.modules.transformer import TransformerDecoderLayer\n",
        "p = 60\n",
        "d_vocab = p+1\n",
        "n_ctx = 3\n",
        "\n",
        "tiny_cfg2 = HookedTransformerConfig(\n",
        "    d_model=64,\n",
        "    d_head=64//1,\n",
        "    n_heads=1,\n",
        "    d_mlp=4*64,\n",
        "    n_layers=1,\n",
        "    n_ctx=n_ctx,\n",
        "    act_fn=\"relu\", #solu_ln\n",
        "    d_vocab=d_vocab,\n",
        "    normalization_type=None, #\"LN\",\n",
        "    seed=23,  # Now we're training a custom model, it's good to set the seed to get reproducible results. It defaults to 42.\n",
        ")\n",
        "\n",
        "tiny_model2 = HookedTransformer(tiny_cfg2).to(device)\n",
        "\n",
        "tiny_optimizer2 = torch.optim.AdamW(tiny_model2.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=1.0)\n",
        "\n",
        "scheduler2 = optim.lr_scheduler.LambdaLR(tiny_optimizer2, lambda step: min(step/10, 1))\n",
        "num_epochs = 20000\n",
        "\n",
        "# Training a model with less integers than there are dimensions in the model\n",
        "train, test = gen_train_test(frac_train=0.7, num=p, seed=0)\n",
        "train = torch.tensor(train)\n",
        "test = torch.tensor(test)\n",
        "\n",
        "fn = lambda x,y,z:min(x,y,z)\n",
        "train_labels = torch.tensor([fn(i, j,k) for i, j, k in train]).to('cuda')\n",
        "test_labels = torch.tensor([fn(i, j,k) for i, j, k  in test]).to('cuda')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "train_model(tiny_model2, train, test, train_labels, test_labels, tiny_optimizer2, scheduler2)"
      ],
      "metadata": {
        "id": "ui4Ia3s_99Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(tiny_model2(torch.tensor([50, 47, 5]))[0][-1])"
      ],
      "metadata": {
        "id": "cgkpDAhDAz1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(OV_copying_score(tiny_model2))\n",
        "print(OV_full_copying_score(tiny_model2))\n",
        "print(embed_unembed_copying_score(tiny_model2))"
      ],
      "metadata": {
        "id": "0Rf5VvWgAL9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}